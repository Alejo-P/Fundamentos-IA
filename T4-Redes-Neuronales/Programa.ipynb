{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "PB8DmW1f9hXI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creacion del DataFrame\n",
        "\n",
        "# Creacion de una lista de 100 elementos con valores aleatorios entre 50 y 120\n",
        "velocidad = [np.round(np.random.uniform(50, 120), 3) for _ in range(100)]\n",
        "# Creacion de una lista de 100 elementos con valores aleatorios entre 0.5 y 4\n",
        "Tiempo = [np.round(np.random.uniform(0.5, 4), 3) for _ in range(100)]\n",
        "# Creacion de una lista vacia para almacenar la distancia\n",
        "distancia = []\n",
        "# Calculo de la distancia recorrida (multiplicando la velocidad por el tiempo)\n",
        "for v, t in zip(velocidad, Tiempo):\n",
        "  d = v * t # Distancia = Velocidad * Tiempo\n",
        "  distancia.append(np.round(d, 3)) # Agregar la distancia a la lista\n",
        "\n",
        "# Creacion del DataFrame con las listas creadas\n",
        "datos = pd.DataFrame({'Velocidad': velocidad, 'Tiempo': Tiempo, 'Distancia': distancia})\n",
        "datos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "baX6ahoC5m3Y",
        "outputId": "567cbff2-6124-4553-9e1d-a83a4e5410d7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Velocidad  Tiempo  Distancia\n",
              "0      66.912   0.717     47.976\n",
              "1     108.613   3.947    428.696\n",
              "2     115.425   1.428    164.827\n",
              "3      80.128   3.131    250.881\n",
              "4      79.184   2.706    214.272\n",
              "..        ...     ...        ...\n",
              "95     58.246   1.270     73.972\n",
              "96    102.515   1.547    158.591\n",
              "97    116.980   3.609    422.181\n",
              "98     87.178   0.843     73.491\n",
              "99     70.421   3.829    269.642\n",
              "\n",
              "[100 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6f3ce4fc-36cc-4c4c-97dd-1df14c7d542a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Velocidad</th>\n",
              "      <th>Tiempo</th>\n",
              "      <th>Distancia</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>66.912</td>\n",
              "      <td>0.717</td>\n",
              "      <td>47.976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>108.613</td>\n",
              "      <td>3.947</td>\n",
              "      <td>428.696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>115.425</td>\n",
              "      <td>1.428</td>\n",
              "      <td>164.827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>80.128</td>\n",
              "      <td>3.131</td>\n",
              "      <td>250.881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>79.184</td>\n",
              "      <td>2.706</td>\n",
              "      <td>214.272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>58.246</td>\n",
              "      <td>1.270</td>\n",
              "      <td>73.972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>102.515</td>\n",
              "      <td>1.547</td>\n",
              "      <td>158.591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>116.980</td>\n",
              "      <td>3.609</td>\n",
              "      <td>422.181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>87.178</td>\n",
              "      <td>0.843</td>\n",
              "      <td>73.491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>70.421</td>\n",
              "      <td>3.829</td>\n",
              "      <td>269.642</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f3ce4fc-36cc-4c4c-97dd-1df14c7d542a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6f3ce4fc-36cc-4c4c-97dd-1df14c7d542a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6f3ce4fc-36cc-4c4c-97dd-1df14c7d542a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fb603b35-94e5-4806-84a7-626e5a980136\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fb603b35-94e5-4806-84a7-626e5a980136')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fb603b35-94e5-4806-84a7-626e5a980136 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_aa77df21-6063-4b70-851b-7340385dcf82\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('datos')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_aa77df21-6063-4b70-851b-7340385dcf82 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('datos');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "datos",
              "summary": "{\n  \"name\": \"datos\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"Velocidad\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20.381187549730086,\n        \"min\": 50.218,\n        \"max\": 119.65,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          89.347,\n          58.12,\n          111.529\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tiempo\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0150827624117427,\n        \"min\": 0.529,\n        \"max\": 3.988,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          0.969,\n          3.427,\n          0.673\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Distancia\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 101.29793276729379,\n        \"min\": 34.315,\n        \"max\": 428.696,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          86.577,\n          199.177,\n          75.059\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separacion en caracteristicas y salidas\n",
        "x = datos[['Velocidad', 'Tiempo']]\n",
        "y = datos['Distancia']"
      ],
      "metadata": {
        "id": "nF7riKPL69Hg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separar los datos en conjuntos de entrenamiento y prueba\n",
        "import sklearn.model_selection as model_selection\n",
        "x_train, x_test, y_train, y_test = model_selection.train_test_split(x, y, test_size=0.3, random_state=50)"
      ],
      "metadata": {
        "id": "7UjvBf_97Fo_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar las bibliotecas necesarias\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Crear el modelo\n",
        "modelo = keras.Sequential([\n",
        "    keras.layers.Dense(units=64, activation='relu', input_shape=[2]),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(units=32, activation='relu'),\n",
        "    keras.layers.Dense(units=16, activation='relu'),\n",
        "    keras.layers.Dense(units=1)\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "modelo.compile(optimizer=\"adam\", loss='mean_squared_error')"
      ],
      "metadata": {
        "id": "KKfcjm2G7P9q",
        "cellView": "code"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizar los datos\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)\n",
        "\n",
        "# Entrenar el modelo\n",
        "historial = modelo.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=1000, batch_size=50, validation_split=0.2)\n",
        "\n",
        "# Evaluar el modelo\n",
        "perdida = modelo.evaluate(x_test, y_test)\n",
        "print(\"Perdida:\", perdida)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyhbuYWCyamd",
        "outputId": "f65d8322-5291-4b47-d238-5529166ce353"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "2/2 [==============================] - 4s 1s/step - loss: 43270.8789 - val_loss: 40324.3906\n",
            "Epoch 2/1000\n",
            "2/2 [==============================] - 0s 110ms/step - loss: 43256.2109 - val_loss: 40303.6484\n",
            "Epoch 3/1000\n",
            "2/2 [==============================] - 0s 208ms/step - loss: 43227.7305 - val_loss: 40282.8906\n",
            "Epoch 4/1000\n",
            "2/2 [==============================] - 0s 143ms/step - loss: 43204.4922 - val_loss: 40261.7539\n",
            "Epoch 5/1000\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 43184.0859 - val_loss: 40239.6953\n",
            "Epoch 6/1000\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 43153.2656 - val_loss: 40216.0898\n",
            "Epoch 7/1000\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 43129.1562 - val_loss: 40191.0625\n",
            "Epoch 8/1000\n",
            "2/2 [==============================] - 0s 158ms/step - loss: 43119.8164 - val_loss: 40164.5508\n",
            "Epoch 9/1000\n",
            "2/2 [==============================] - 0s 217ms/step - loss: 43073.6719 - val_loss: 40136.0664\n",
            "Epoch 10/1000\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 43039.9297 - val_loss: 40105.5742\n",
            "Epoch 11/1000\n",
            "2/2 [==============================] - 0s 196ms/step - loss: 43013.5859 - val_loss: 40072.6484\n",
            "Epoch 12/1000\n",
            "2/2 [==============================] - 0s 256ms/step - loss: 42966.5703 - val_loss: 40037.0977\n",
            "Epoch 13/1000\n",
            "2/2 [==============================] - 0s 144ms/step - loss: 42931.5273 - val_loss: 39999.0508\n",
            "Epoch 14/1000\n",
            "2/2 [==============================] - 0s 151ms/step - loss: 42872.0781 - val_loss: 39957.7773\n",
            "Epoch 15/1000\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 42813.9375 - val_loss: 39912.9219\n",
            "Epoch 16/1000\n",
            "2/2 [==============================] - 0s 123ms/step - loss: 42766.5117 - val_loss: 39863.8555\n",
            "Epoch 17/1000\n",
            "2/2 [==============================] - 0s 106ms/step - loss: 42725.7812 - val_loss: 39810.0000\n",
            "Epoch 18/1000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 42664.6836 - val_loss: 39751.4023\n",
            "Epoch 19/1000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 42596.5391 - val_loss: 39687.4297\n",
            "Epoch 20/1000\n",
            "2/2 [==============================] - 0s 132ms/step - loss: 42529.7930 - val_loss: 39617.7266\n",
            "Epoch 21/1000\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 42473.5781 - val_loss: 39543.0117\n",
            "Epoch 22/1000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 42357.7773 - val_loss: 39463.0508\n",
            "Epoch 23/1000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 42251.7461 - val_loss: 39376.2695\n",
            "Epoch 24/1000\n",
            "2/2 [==============================] - 0s 114ms/step - loss: 42207.1484 - val_loss: 39282.3555\n",
            "Epoch 25/1000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 42052.1602 - val_loss: 39180.4180\n",
            "Epoch 26/1000\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 41949.7969 - val_loss: 39070.3984\n",
            "Epoch 27/1000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 41809.3438 - val_loss: 38951.0234\n",
            "Epoch 28/1000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 41667.8711 - val_loss: 38820.8516\n",
            "Epoch 29/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 41511.0508 - val_loss: 38680.1172\n",
            "Epoch 30/1000\n",
            "2/2 [==============================] - 0s 141ms/step - loss: 41381.0273 - val_loss: 38527.2852\n",
            "Epoch 31/1000\n",
            "2/2 [==============================] - 0s 127ms/step - loss: 41214.5195 - val_loss: 38362.3242\n",
            "Epoch 32/1000\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 40996.7617 - val_loss: 38184.5469\n",
            "Epoch 33/1000\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 40841.8555 - val_loss: 37995.3320\n",
            "Epoch 34/1000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 40601.9766 - val_loss: 37791.1875\n",
            "Epoch 35/1000\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 40373.9844 - val_loss: 37570.9141\n",
            "Epoch 36/1000\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 40156.4414 - val_loss: 37333.5156\n",
            "Epoch 37/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 39759.9492 - val_loss: 37077.6953\n",
            "Epoch 38/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 39506.7500 - val_loss: 36802.7500\n",
            "Epoch 39/1000\n",
            "2/2 [==============================] - 0s 156ms/step - loss: 39283.0820 - val_loss: 36506.9961\n",
            "Epoch 40/1000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 38989.9844 - val_loss: 36190.6602\n",
            "Epoch 41/1000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 38543.7773 - val_loss: 35851.5508\n",
            "Epoch 42/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 37978.7695 - val_loss: 35486.0273\n",
            "Epoch 43/1000\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 37686.5703 - val_loss: 35095.1328\n",
            "Epoch 44/1000\n",
            "2/2 [==============================] - 0s 114ms/step - loss: 37350.5117 - val_loss: 34681.8750\n",
            "Epoch 45/1000\n",
            "2/2 [==============================] - 0s 106ms/step - loss: 36655.5938 - val_loss: 34245.3203\n",
            "Epoch 46/1000\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 36504.4062 - val_loss: 33783.2070\n",
            "Epoch 47/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 35692.9570 - val_loss: 33294.4570\n",
            "Epoch 48/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 35197.0625 - val_loss: 32779.2852\n",
            "Epoch 49/1000\n",
            "2/2 [==============================] - 0s 97ms/step - loss: 34776.3203 - val_loss: 32239.4316\n",
            "Epoch 50/1000\n",
            "2/2 [==============================] - 0s 139ms/step - loss: 34055.8828 - val_loss: 31671.9727\n",
            "Epoch 51/1000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 33590.7656 - val_loss: 31077.9590\n",
            "Epoch 52/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 32735.3438 - val_loss: 30451.6797\n",
            "Epoch 53/1000\n",
            "2/2 [==============================] - 0s 138ms/step - loss: 32106.1328 - val_loss: 29790.9688\n",
            "Epoch 54/1000\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 31346.5723 - val_loss: 29105.0664\n",
            "Epoch 55/1000\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 30995.4102 - val_loss: 28383.8438\n",
            "Epoch 56/1000\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 29929.3770 - val_loss: 27635.4902\n",
            "Epoch 57/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 28716.0039 - val_loss: 26845.3965\n",
            "Epoch 58/1000\n",
            "2/2 [==============================] - 0s 134ms/step - loss: 27983.5781 - val_loss: 26025.3574\n",
            "Epoch 59/1000\n",
            "2/2 [==============================] - 0s 141ms/step - loss: 27094.5098 - val_loss: 25170.0352\n",
            "Epoch 60/1000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 26099.2070 - val_loss: 24301.8008\n",
            "Epoch 61/1000\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 25056.9492 - val_loss: 23419.5723\n",
            "Epoch 62/1000\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 24392.2402 - val_loss: 22511.3008\n",
            "Epoch 63/1000\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 23383.8789 - val_loss: 21584.8262\n",
            "Epoch 64/1000\n",
            "2/2 [==============================] - 0s 101ms/step - loss: 21878.8906 - val_loss: 20634.0918\n",
            "Epoch 65/1000\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 21281.1562 - val_loss: 19660.8809\n",
            "Epoch 66/1000\n",
            "2/2 [==============================] - 0s 122ms/step - loss: 19505.6699 - val_loss: 18672.2363\n",
            "Epoch 67/1000\n",
            "2/2 [==============================] - 0s 107ms/step - loss: 19224.1445 - val_loss: 17686.3008\n",
            "Epoch 68/1000\n",
            "2/2 [==============================] - 0s 113ms/step - loss: 17597.4023 - val_loss: 16690.7754\n",
            "Epoch 69/1000\n",
            "2/2 [==============================] - 0s 111ms/step - loss: 17091.9473 - val_loss: 15687.3877\n",
            "Epoch 70/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 15789.4443 - val_loss: 14685.7617\n",
            "Epoch 71/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 14499.8164 - val_loss: 13695.6006\n",
            "Epoch 72/1000\n",
            "2/2 [==============================] - 0s 96ms/step - loss: 13966.0371 - val_loss: 12710.0303\n",
            "Epoch 73/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 12951.5371 - val_loss: 11738.9355\n",
            "Epoch 74/1000\n",
            "2/2 [==============================] - 0s 102ms/step - loss: 11872.7510 - val_loss: 10783.8369\n",
            "Epoch 75/1000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 10308.2324 - val_loss: 9862.4814\n",
            "Epoch 76/1000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 9377.1123 - val_loss: 8965.3213\n",
            "Epoch 77/1000\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 8808.3193 - val_loss: 8107.3208\n",
            "Epoch 78/1000\n",
            "2/2 [==============================] - 0s 105ms/step - loss: 8056.7837 - val_loss: 7282.8315\n",
            "Epoch 79/1000\n",
            "2/2 [==============================] - 0s 154ms/step - loss: 6875.6587 - val_loss: 6497.9111\n",
            "Epoch 80/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 5827.9912 - val_loss: 5756.2549\n",
            "Epoch 81/1000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 5475.1440 - val_loss: 5062.8394\n",
            "Epoch 82/1000\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 4812.4473 - val_loss: 4426.8042\n",
            "Epoch 83/1000\n",
            "2/2 [==============================] - 0s 100ms/step - loss: 3879.2446 - val_loss: 3844.4722\n",
            "Epoch 84/1000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 3344.2053 - val_loss: 3319.0190\n",
            "Epoch 85/1000\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 3184.9727 - val_loss: 2855.3958\n",
            "Epoch 86/1000\n",
            "2/2 [==============================] - 0s 99ms/step - loss: 2746.5271 - val_loss: 2434.4761\n",
            "Epoch 87/1000\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 2053.9668 - val_loss: 2069.2124\n",
            "Epoch 88/1000\n",
            "2/2 [==============================] - 0s 215ms/step - loss: 1801.0631 - val_loss: 1756.9380\n",
            "Epoch 89/1000\n",
            "2/2 [==============================] - 0s 108ms/step - loss: 1588.1498 - val_loss: 1495.8403\n",
            "Epoch 90/1000\n",
            "2/2 [==============================] - 0s 130ms/step - loss: 1569.2869 - val_loss: 1281.1362\n",
            "Epoch 91/1000\n",
            "2/2 [==============================] - 0s 155ms/step - loss: 1378.8939 - val_loss: 1107.8424\n",
            "Epoch 92/1000\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 1307.7339 - val_loss: 969.2284\n",
            "Epoch 93/1000\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 1248.8098 - val_loss: 860.1036\n",
            "Epoch 94/1000\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 1016.6980 - val_loss: 776.0956\n",
            "Epoch 95/1000\n",
            "2/2 [==============================] - 0s 140ms/step - loss: 1158.5107 - val_loss: 710.1205\n",
            "Epoch 96/1000\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 1162.5663 - val_loss: 658.9750\n",
            "Epoch 97/1000\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 958.6349 - val_loss: 622.8240\n",
            "Epoch 98/1000\n",
            "2/2 [==============================] - 0s 98ms/step - loss: 918.9731 - val_loss: 593.9539\n",
            "Epoch 99/1000\n",
            "2/2 [==============================] - 0s 120ms/step - loss: 1021.5644 - val_loss: 568.5829\n",
            "Epoch 100/1000\n",
            "2/2 [==============================] - 0s 143ms/step - loss: 1040.4724 - val_loss: 547.3346\n",
            "Epoch 101/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 932.7499 - val_loss: 528.1776\n",
            "Epoch 102/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 900.8058 - val_loss: 512.1524\n",
            "Epoch 103/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1119.6339 - val_loss: 499.0772\n",
            "Epoch 104/1000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 838.1141 - val_loss: 487.2024\n",
            "Epoch 105/1000\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 858.3087 - val_loss: 477.5973\n",
            "Epoch 106/1000\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 1078.4381 - val_loss: 469.2710\n",
            "Epoch 107/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 1082.3790 - val_loss: 463.6650\n",
            "Epoch 108/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 995.5688 - val_loss: 459.1352\n",
            "Epoch 109/1000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 992.5342 - val_loss: 454.9489\n",
            "Epoch 110/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 860.0175 - val_loss: 451.7381\n",
            "Epoch 111/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 763.2313 - val_loss: 447.5400\n",
            "Epoch 112/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 971.4437 - val_loss: 443.8013\n",
            "Epoch 113/1000\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 838.6645 - val_loss: 442.7057\n",
            "Epoch 114/1000\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 689.5739 - val_loss: 442.3458\n",
            "Epoch 115/1000\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 895.9471 - val_loss: 441.3603\n",
            "Epoch 116/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 915.8491 - val_loss: 439.1093\n",
            "Epoch 117/1000\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 710.8752 - val_loss: 435.5050\n",
            "Epoch 118/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 886.8947 - val_loss: 430.9076\n",
            "Epoch 119/1000\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 850.1353 - val_loss: 425.4977\n",
            "Epoch 120/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 912.5418 - val_loss: 420.4943\n",
            "Epoch 121/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 826.2634 - val_loss: 413.8427\n",
            "Epoch 122/1000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 783.7274 - val_loss: 407.6976\n",
            "Epoch 123/1000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 764.0960 - val_loss: 401.9359\n",
            "Epoch 124/1000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 893.3610 - val_loss: 395.5931\n",
            "Epoch 125/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 727.2514 - val_loss: 389.4610\n",
            "Epoch 126/1000\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 817.4189 - val_loss: 384.4294\n",
            "Epoch 127/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 815.2071 - val_loss: 379.6692\n",
            "Epoch 128/1000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 719.7147 - val_loss: 374.2455\n",
            "Epoch 129/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 564.5565 - val_loss: 368.8280\n",
            "Epoch 130/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 766.0072 - val_loss: 362.6157\n",
            "Epoch 131/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 945.5701 - val_loss: 355.7296\n",
            "Epoch 132/1000\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 663.8881 - val_loss: 347.8771\n",
            "Epoch 133/1000\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 888.0311 - val_loss: 341.8808\n",
            "Epoch 134/1000\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 679.2988 - val_loss: 337.5285\n",
            "Epoch 135/1000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 738.3241 - val_loss: 333.3419\n",
            "Epoch 136/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 684.8585 - val_loss: 330.1805\n",
            "Epoch 137/1000\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 732.4743 - val_loss: 328.1238\n",
            "Epoch 138/1000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 702.9809 - val_loss: 327.1103\n",
            "Epoch 139/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 643.6288 - val_loss: 325.2778\n",
            "Epoch 140/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 708.6414 - val_loss: 324.4141\n",
            "Epoch 141/1000\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 674.8155 - val_loss: 323.6584\n",
            "Epoch 142/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 670.2053 - val_loss: 323.7825\n",
            "Epoch 143/1000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 833.5220 - val_loss: 325.8879\n",
            "Epoch 144/1000\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 781.5581 - val_loss: 329.6145\n",
            "Epoch 145/1000\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 916.9255 - val_loss: 331.1848\n",
            "Epoch 146/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 647.3704 - val_loss: 331.2812\n",
            "Epoch 147/1000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 695.5055 - val_loss: 331.6889\n",
            "Epoch 148/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 639.3994 - val_loss: 332.9007\n",
            "Epoch 149/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 625.5726 - val_loss: 333.1254\n",
            "Epoch 150/1000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 901.1321 - val_loss: 332.5630\n",
            "Epoch 151/1000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 749.3377 - val_loss: 329.7248\n",
            "Epoch 152/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 585.4772 - val_loss: 326.0782\n",
            "Epoch 153/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 935.6671 - val_loss: 321.6294\n",
            "Epoch 154/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 715.4410 - val_loss: 315.7351\n",
            "Epoch 155/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 766.4448 - val_loss: 309.6821\n",
            "Epoch 156/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 670.6130 - val_loss: 303.4228\n",
            "Epoch 157/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 680.1313 - val_loss: 297.7291\n",
            "Epoch 158/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 692.7567 - val_loss: 292.4383\n",
            "Epoch 159/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 684.7576 - val_loss: 287.4522\n",
            "Epoch 160/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 605.6310 - val_loss: 282.7379\n",
            "Epoch 161/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 687.5322 - val_loss: 279.7376\n",
            "Epoch 162/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 841.5287 - val_loss: 278.7735\n",
            "Epoch 163/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 622.0291 - val_loss: 277.5196\n",
            "Epoch 164/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 465.1035 - val_loss: 276.1301\n",
            "Epoch 165/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 614.1808 - val_loss: 274.8102\n",
            "Epoch 166/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 498.4491 - val_loss: 273.5829\n",
            "Epoch 167/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 508.5449 - val_loss: 271.6898\n",
            "Epoch 168/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 594.8027 - val_loss: 270.5172\n",
            "Epoch 169/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 643.4839 - val_loss: 268.7148\n",
            "Epoch 170/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 666.2794 - val_loss: 265.7055\n",
            "Epoch 171/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 614.7861 - val_loss: 262.6370\n",
            "Epoch 172/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 622.5488 - val_loss: 261.3173\n",
            "Epoch 173/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 546.8530 - val_loss: 260.2818\n",
            "Epoch 174/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 677.6917 - val_loss: 259.1831\n",
            "Epoch 175/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 562.5222 - val_loss: 257.8188\n",
            "Epoch 176/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 666.7383 - val_loss: 258.0489\n",
            "Epoch 177/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 545.5051 - val_loss: 258.4174\n",
            "Epoch 178/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 707.0386 - val_loss: 258.2050\n",
            "Epoch 179/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 553.2280 - val_loss: 258.4717\n",
            "Epoch 180/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 640.4225 - val_loss: 258.1564\n",
            "Epoch 181/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 636.3961 - val_loss: 257.3226\n",
            "Epoch 182/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 695.4724 - val_loss: 257.1733\n",
            "Epoch 183/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 524.7220 - val_loss: 257.2029\n",
            "Epoch 184/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 574.4539 - val_loss: 256.2418\n",
            "Epoch 185/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 604.1860 - val_loss: 254.0751\n",
            "Epoch 186/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 618.5345 - val_loss: 250.5453\n",
            "Epoch 187/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 521.9244 - val_loss: 246.1024\n",
            "Epoch 188/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 513.7826 - val_loss: 241.1467\n",
            "Epoch 189/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 593.4139 - val_loss: 236.6475\n",
            "Epoch 190/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 650.2057 - val_loss: 232.3537\n",
            "Epoch 191/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 502.2372 - val_loss: 228.8861\n",
            "Epoch 192/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 555.3057 - val_loss: 226.0317\n",
            "Epoch 193/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 585.9891 - val_loss: 224.7297\n",
            "Epoch 194/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 625.3008 - val_loss: 223.5974\n",
            "Epoch 195/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 686.1221 - val_loss: 222.2232\n",
            "Epoch 196/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 630.3314 - val_loss: 221.0357\n",
            "Epoch 197/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 633.5519 - val_loss: 219.7979\n",
            "Epoch 198/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 562.9721 - val_loss: 218.4956\n",
            "Epoch 199/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 546.1056 - val_loss: 217.2265\n",
            "Epoch 200/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 468.9122 - val_loss: 217.1514\n",
            "Epoch 201/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 610.7327 - val_loss: 216.8512\n",
            "Epoch 202/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 580.5224 - val_loss: 215.8250\n",
            "Epoch 203/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 595.1743 - val_loss: 213.5292\n",
            "Epoch 204/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 563.4256 - val_loss: 211.1981\n",
            "Epoch 205/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 446.4838 - val_loss: 208.9750\n",
            "Epoch 206/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 617.0765 - val_loss: 206.7593\n",
            "Epoch 207/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 552.3510 - val_loss: 204.8950\n",
            "Epoch 208/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 489.9518 - val_loss: 203.4605\n",
            "Epoch 209/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 563.4234 - val_loss: 202.7059\n",
            "Epoch 210/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 509.3761 - val_loss: 202.9426\n",
            "Epoch 211/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 545.9941 - val_loss: 202.5963\n",
            "Epoch 212/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 630.9252 - val_loss: 202.6043\n",
            "Epoch 213/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 458.0651 - val_loss: 202.4298\n",
            "Epoch 214/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 583.5981 - val_loss: 203.6211\n",
            "Epoch 215/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 583.8407 - val_loss: 204.7555\n",
            "Epoch 216/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 554.1511 - val_loss: 204.4631\n",
            "Epoch 217/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 523.0589 - val_loss: 203.1619\n",
            "Epoch 218/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 488.5608 - val_loss: 201.0413\n",
            "Epoch 219/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 651.4139 - val_loss: 199.9698\n",
            "Epoch 220/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 483.1586 - val_loss: 200.0694\n",
            "Epoch 221/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 628.3079 - val_loss: 200.5122\n",
            "Epoch 222/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 384.2590 - val_loss: 201.0842\n",
            "Epoch 223/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 516.3942 - val_loss: 200.3146\n",
            "Epoch 224/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 477.8773 - val_loss: 198.5025\n",
            "Epoch 225/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 470.6233 - val_loss: 196.2893\n",
            "Epoch 226/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 535.4496 - val_loss: 194.0073\n",
            "Epoch 227/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 628.4952 - val_loss: 192.1569\n",
            "Epoch 228/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 478.9626 - val_loss: 190.6352\n",
            "Epoch 229/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 566.0468 - val_loss: 189.9863\n",
            "Epoch 230/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 600.4270 - val_loss: 189.0308\n",
            "Epoch 231/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 489.7753 - val_loss: 188.0857\n",
            "Epoch 232/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 528.8529 - val_loss: 187.3372\n",
            "Epoch 233/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 450.4561 - val_loss: 186.7247\n",
            "Epoch 234/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 408.9586 - val_loss: 186.5830\n",
            "Epoch 235/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 452.9956 - val_loss: 187.2705\n",
            "Epoch 236/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 525.2977 - val_loss: 187.7272\n",
            "Epoch 237/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 582.3209 - val_loss: 187.5291\n",
            "Epoch 238/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 458.3466 - val_loss: 187.8611\n",
            "Epoch 239/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 395.4156 - val_loss: 188.3259\n",
            "Epoch 240/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 622.5657 - val_loss: 188.5134\n",
            "Epoch 241/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 443.8959 - val_loss: 188.5767\n",
            "Epoch 242/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 574.6611 - val_loss: 187.5124\n",
            "Epoch 243/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 628.8696 - val_loss: 185.1985\n",
            "Epoch 244/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 525.3410 - val_loss: 183.4178\n",
            "Epoch 245/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 516.7186 - val_loss: 182.1240\n",
            "Epoch 246/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 512.1061 - val_loss: 181.7276\n",
            "Epoch 247/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 603.0154 - val_loss: 181.0135\n",
            "Epoch 248/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 531.2648 - val_loss: 179.4425\n",
            "Epoch 249/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 503.4091 - val_loss: 178.0119\n",
            "Epoch 250/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 554.3814 - val_loss: 176.4346\n",
            "Epoch 251/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 388.1631 - val_loss: 174.7793\n",
            "Epoch 252/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 444.1249 - val_loss: 173.3826\n",
            "Epoch 253/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 445.8394 - val_loss: 172.0994\n",
            "Epoch 254/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 377.3489 - val_loss: 170.9440\n",
            "Epoch 255/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 568.8820 - val_loss: 169.1025\n",
            "Epoch 256/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 435.3621 - val_loss: 167.4981\n",
            "Epoch 257/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 462.7619 - val_loss: 166.1262\n",
            "Epoch 258/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 668.2960 - val_loss: 164.8105\n",
            "Epoch 259/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 420.3546 - val_loss: 164.0064\n",
            "Epoch 260/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 546.8774 - val_loss: 163.4901\n",
            "Epoch 261/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 498.8654 - val_loss: 162.8764\n",
            "Epoch 262/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 506.5964 - val_loss: 162.3626\n",
            "Epoch 263/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 538.5861 - val_loss: 162.2297\n",
            "Epoch 264/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 582.9397 - val_loss: 161.6440\n",
            "Epoch 265/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 540.8184 - val_loss: 160.9451\n",
            "Epoch 266/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 412.3822 - val_loss: 160.5741\n",
            "Epoch 267/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 449.2107 - val_loss: 160.1801\n",
            "Epoch 268/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 397.6840 - val_loss: 159.6904\n",
            "Epoch 269/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 493.4454 - val_loss: 158.8488\n",
            "Epoch 270/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 319.6962 - val_loss: 157.6573\n",
            "Epoch 271/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 439.9134 - val_loss: 156.4194\n",
            "Epoch 272/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 463.9447 - val_loss: 155.7686\n",
            "Epoch 273/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 383.3397 - val_loss: 155.6635\n",
            "Epoch 274/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 471.8565 - val_loss: 155.0994\n",
            "Epoch 275/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 300.6107 - val_loss: 154.7631\n",
            "Epoch 276/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 437.1379 - val_loss: 154.7280\n",
            "Epoch 277/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 403.0888 - val_loss: 154.7828\n",
            "Epoch 278/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 395.7954 - val_loss: 154.6321\n",
            "Epoch 279/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 490.5474 - val_loss: 154.3303\n",
            "Epoch 280/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 577.6531 - val_loss: 154.0285\n",
            "Epoch 281/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 418.7466 - val_loss: 153.6255\n",
            "Epoch 282/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 323.4890 - val_loss: 153.3073\n",
            "Epoch 283/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 399.6368 - val_loss: 153.5763\n",
            "Epoch 284/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 571.8534 - val_loss: 153.8002\n",
            "Epoch 285/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 322.6997 - val_loss: 153.8953\n",
            "Epoch 286/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 333.2447 - val_loss: 154.4529\n",
            "Epoch 287/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 436.7605 - val_loss: 155.1087\n",
            "Epoch 288/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 505.0503 - val_loss: 155.6896\n",
            "Epoch 289/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 413.5367 - val_loss: 155.3273\n",
            "Epoch 290/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 408.2822 - val_loss: 154.1131\n",
            "Epoch 291/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 534.5468 - val_loss: 152.3805\n",
            "Epoch 292/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 623.1779 - val_loss: 150.8137\n",
            "Epoch 293/1000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 315.3257 - val_loss: 149.6831\n",
            "Epoch 294/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 334.8597 - val_loss: 149.4099\n",
            "Epoch 295/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 417.4356 - val_loss: 148.8463\n",
            "Epoch 296/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 482.4995 - val_loss: 147.6340\n",
            "Epoch 297/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 345.1583 - val_loss: 146.6046\n",
            "Epoch 298/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 491.0754 - val_loss: 145.3313\n",
            "Epoch 299/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 542.8589 - val_loss: 143.8679\n",
            "Epoch 300/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 277.9035 - val_loss: 142.5645\n",
            "Epoch 301/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 451.4808 - val_loss: 141.4838\n",
            "Epoch 302/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 354.7111 - val_loss: 140.6409\n",
            "Epoch 303/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 380.3835 - val_loss: 139.8162\n",
            "Epoch 304/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 400.2737 - val_loss: 139.0771\n",
            "Epoch 305/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 440.6065 - val_loss: 138.3941\n",
            "Epoch 306/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 538.4300 - val_loss: 137.6012\n",
            "Epoch 307/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 493.7502 - val_loss: 136.9831\n",
            "Epoch 308/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 568.2293 - val_loss: 136.5024\n",
            "Epoch 309/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 405.5234 - val_loss: 135.5523\n",
            "Epoch 310/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 639.3250 - val_loss: 134.5097\n",
            "Epoch 311/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 385.0498 - val_loss: 133.3346\n",
            "Epoch 312/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 437.6425 - val_loss: 132.4577\n",
            "Epoch 313/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 424.6515 - val_loss: 131.9541\n",
            "Epoch 314/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 449.5359 - val_loss: 131.7975\n",
            "Epoch 315/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 411.7247 - val_loss: 131.5543\n",
            "Epoch 316/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 391.3348 - val_loss: 131.5365\n",
            "Epoch 317/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 438.4066 - val_loss: 131.6800\n",
            "Epoch 318/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 358.2123 - val_loss: 131.6820\n",
            "Epoch 319/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 339.7906 - val_loss: 132.2728\n",
            "Epoch 320/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 557.7002 - val_loss: 133.0002\n",
            "Epoch 321/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 422.5566 - val_loss: 134.4670\n",
            "Epoch 322/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 432.7275 - val_loss: 135.8250\n",
            "Epoch 323/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 452.8611 - val_loss: 137.4946\n",
            "Epoch 324/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 352.5968 - val_loss: 138.9505\n",
            "Epoch 325/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 370.5244 - val_loss: 140.3180\n",
            "Epoch 326/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 457.1068 - val_loss: 140.8358\n",
            "Epoch 327/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 286.8966 - val_loss: 141.0945\n",
            "Epoch 328/1000\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 424.8025 - val_loss: 140.3597\n",
            "Epoch 329/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 560.4233 - val_loss: 139.2087\n",
            "Epoch 330/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 428.7766 - val_loss: 137.8990\n",
            "Epoch 331/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 336.8007 - val_loss: 136.8122\n",
            "Epoch 332/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 337.4142 - val_loss: 136.1844\n",
            "Epoch 333/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 261.9246 - val_loss: 136.0163\n",
            "Epoch 334/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 439.7817 - val_loss: 136.0162\n",
            "Epoch 335/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 352.8381 - val_loss: 136.0966\n",
            "Epoch 336/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 439.6280 - val_loss: 136.0763\n",
            "Epoch 337/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 492.1194 - val_loss: 135.6516\n",
            "Epoch 338/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 294.9458 - val_loss: 134.6250\n",
            "Epoch 339/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 397.4533 - val_loss: 133.6310\n",
            "Epoch 340/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 404.6752 - val_loss: 133.2474\n",
            "Epoch 341/1000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 408.2661 - val_loss: 132.8938\n",
            "Epoch 342/1000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 360.8526 - val_loss: 132.7872\n",
            "Epoch 343/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 359.3624 - val_loss: 132.9657\n",
            "Epoch 344/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 361.9615 - val_loss: 132.9583\n",
            "Epoch 345/1000\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 427.4409 - val_loss: 132.9375\n",
            "Epoch 346/1000\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 355.2119 - val_loss: 133.0569\n",
            "Epoch 347/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 354.0450 - val_loss: 134.7700\n",
            "Epoch 348/1000\n",
            "2/2 [==============================] - 0s 96ms/step - loss: 334.1770 - val_loss: 136.0165\n",
            "Epoch 349/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 400.8606 - val_loss: 136.5597\n",
            "Epoch 350/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 347.7747 - val_loss: 136.0211\n",
            "Epoch 351/1000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 365.0268 - val_loss: 134.3368\n",
            "Epoch 352/1000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 388.1850 - val_loss: 132.6125\n",
            "Epoch 353/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 368.9364 - val_loss: 131.0204\n",
            "Epoch 354/1000\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 505.3732 - val_loss: 129.7587\n",
            "Epoch 355/1000\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 446.8286 - val_loss: 128.7611\n",
            "Epoch 356/1000\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 341.4639 - val_loss: 127.8801\n",
            "Epoch 357/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 588.3122 - val_loss: 126.9223\n",
            "Epoch 358/1000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 325.0190 - val_loss: 126.1608\n",
            "Epoch 359/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 325.0302 - val_loss: 125.3376\n",
            "Epoch 360/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 337.7951 - val_loss: 124.6857\n",
            "Epoch 361/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 363.4854 - val_loss: 123.9571\n",
            "Epoch 362/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 429.8553 - val_loss: 123.7769\n",
            "Epoch 363/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 385.0360 - val_loss: 123.7702\n",
            "Epoch 364/1000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 302.3393 - val_loss: 123.8472\n",
            "Epoch 365/1000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 440.1671 - val_loss: 123.8144\n",
            "Epoch 366/1000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 425.3273 - val_loss: 123.1002\n",
            "Epoch 367/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 488.7013 - val_loss: 121.7289\n",
            "Epoch 368/1000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 385.8348 - val_loss: 120.4704\n",
            "Epoch 369/1000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 361.0674 - val_loss: 119.9435\n",
            "Epoch 370/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 263.8814 - val_loss: 119.8235\n",
            "Epoch 371/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 413.4768 - val_loss: 119.2492\n",
            "Epoch 372/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 418.6796 - val_loss: 118.6359\n",
            "Epoch 373/1000\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 386.8133 - val_loss: 117.9145\n",
            "Epoch 374/1000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 295.1375 - val_loss: 117.3100\n",
            "Epoch 375/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 337.0946 - val_loss: 116.7308\n",
            "Epoch 376/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 446.9065 - val_loss: 116.2368\n",
            "Epoch 377/1000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 388.3460 - val_loss: 116.2539\n",
            "Epoch 378/1000\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 324.2186 - val_loss: 116.8137\n",
            "Epoch 379/1000\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 292.0180 - val_loss: 117.7719\n",
            "Epoch 380/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 357.2719 - val_loss: 118.2648\n",
            "Epoch 381/1000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 351.3001 - val_loss: 118.0287\n",
            "Epoch 382/1000\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 376.1620 - val_loss: 117.8470\n",
            "Epoch 383/1000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 303.9414 - val_loss: 118.4107\n",
            "Epoch 384/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 356.3996 - val_loss: 119.3817\n",
            "Epoch 385/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 499.6688 - val_loss: 118.9456\n",
            "Epoch 386/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 306.7033 - val_loss: 118.2529\n",
            "Epoch 387/1000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 341.8378 - val_loss: 118.5414\n",
            "Epoch 388/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 455.1780 - val_loss: 118.5698\n",
            "Epoch 389/1000\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 317.2334 - val_loss: 118.5656\n",
            "Epoch 390/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 414.4680 - val_loss: 118.5888\n",
            "Epoch 391/1000\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 265.8233 - val_loss: 118.7449\n",
            "Epoch 392/1000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 344.1769 - val_loss: 119.0672\n",
            "Epoch 393/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 329.3004 - val_loss: 119.4918\n",
            "Epoch 394/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 340.1724 - val_loss: 120.1334\n",
            "Epoch 395/1000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 414.6779 - val_loss: 120.8184\n",
            "Epoch 396/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 360.9139 - val_loss: 121.3764\n",
            "Epoch 397/1000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 317.6116 - val_loss: 121.8476\n",
            "Epoch 398/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 339.2082 - val_loss: 122.1399\n",
            "Epoch 399/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 253.5956 - val_loss: 122.2771\n",
            "Epoch 400/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 344.3827 - val_loss: 122.6615\n",
            "Epoch 401/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 381.7076 - val_loss: 123.4884\n",
            "Epoch 402/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 301.7880 - val_loss: 124.1852\n",
            "Epoch 403/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 404.3794 - val_loss: 125.0691\n",
            "Epoch 404/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 376.3901 - val_loss: 125.8086\n",
            "Epoch 405/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 346.7851 - val_loss: 126.3718\n",
            "Epoch 406/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 387.7966 - val_loss: 126.1423\n",
            "Epoch 407/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 276.8395 - val_loss: 125.7612\n",
            "Epoch 408/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 329.9673 - val_loss: 125.5816\n",
            "Epoch 409/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 335.4516 - val_loss: 125.5734\n",
            "Epoch 410/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 329.1845 - val_loss: 125.5131\n",
            "Epoch 411/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 384.4921 - val_loss: 125.4764\n",
            "Epoch 412/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 222.0255 - val_loss: 125.7170\n",
            "Epoch 413/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 286.9089 - val_loss: 125.7967\n",
            "Epoch 414/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 237.7102 - val_loss: 126.2978\n",
            "Epoch 415/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 362.8678 - val_loss: 126.7040\n",
            "Epoch 416/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 399.1294 - val_loss: 126.8712\n",
            "Epoch 417/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 441.7631 - val_loss: 126.9415\n",
            "Epoch 418/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 331.7856 - val_loss: 125.5246\n",
            "Epoch 419/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 373.8734 - val_loss: 123.3837\n",
            "Epoch 420/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 316.2055 - val_loss: 121.3141\n",
            "Epoch 421/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 325.9168 - val_loss: 119.5170\n",
            "Epoch 422/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 374.9361 - val_loss: 118.1375\n",
            "Epoch 423/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 441.0867 - val_loss: 117.1210\n",
            "Epoch 424/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 385.7387 - val_loss: 116.3957\n",
            "Epoch 425/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 363.4662 - val_loss: 116.1394\n",
            "Epoch 426/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 333.9523 - val_loss: 115.7673\n",
            "Epoch 427/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 219.6562 - val_loss: 115.9202\n",
            "Epoch 428/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 423.9373 - val_loss: 116.1668\n",
            "Epoch 429/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 235.2130 - val_loss: 116.4234\n",
            "Epoch 430/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 373.1681 - val_loss: 117.0971\n",
            "Epoch 431/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 307.0669 - val_loss: 118.1760\n",
            "Epoch 432/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 300.5255 - val_loss: 119.5160\n",
            "Epoch 433/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 379.1657 - val_loss: 120.4420\n",
            "Epoch 434/1000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 313.2840 - val_loss: 120.6085\n",
            "Epoch 435/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 375.8358 - val_loss: 120.1265\n",
            "Epoch 436/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 405.0166 - val_loss: 119.6399\n",
            "Epoch 437/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 414.3722 - val_loss: 119.0397\n",
            "Epoch 438/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 293.2008 - val_loss: 119.4385\n",
            "Epoch 439/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 277.4190 - val_loss: 120.2694\n",
            "Epoch 440/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 258.3234 - val_loss: 121.1416\n",
            "Epoch 441/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 346.0373 - val_loss: 121.2183\n",
            "Epoch 442/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 267.9582 - val_loss: 121.2476\n",
            "Epoch 443/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 278.7488 - val_loss: 121.4800\n",
            "Epoch 444/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 387.6941 - val_loss: 122.3435\n",
            "Epoch 445/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 375.8362 - val_loss: 123.5747\n",
            "Epoch 446/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 368.3863 - val_loss: 123.6424\n",
            "Epoch 447/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 344.9550 - val_loss: 124.0441\n",
            "Epoch 448/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 309.6127 - val_loss: 124.3257\n",
            "Epoch 449/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 263.0458 - val_loss: 123.6358\n",
            "Epoch 450/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 318.8310 - val_loss: 122.4305\n",
            "Epoch 451/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 380.8349 - val_loss: 121.1842\n",
            "Epoch 452/1000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 322.8794 - val_loss: 120.6145\n",
            "Epoch 453/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 278.2085 - val_loss: 120.2372\n",
            "Epoch 454/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 382.2292 - val_loss: 119.4192\n",
            "Epoch 455/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 354.3027 - val_loss: 118.5414\n",
            "Epoch 456/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 443.0933 - val_loss: 117.5460\n",
            "Epoch 457/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 341.5834 - val_loss: 116.2809\n",
            "Epoch 458/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 236.6336 - val_loss: 115.4423\n",
            "Epoch 459/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 337.2723 - val_loss: 115.0212\n",
            "Epoch 460/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 310.7346 - val_loss: 114.8640\n",
            "Epoch 461/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 384.3736 - val_loss: 115.1180\n",
            "Epoch 462/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 357.4722 - val_loss: 115.2792\n",
            "Epoch 463/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 351.9823 - val_loss: 115.2951\n",
            "Epoch 464/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 536.9147 - val_loss: 115.6034\n",
            "Epoch 465/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 331.2887 - val_loss: 114.9525\n",
            "Epoch 466/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 389.3078 - val_loss: 114.1386\n",
            "Epoch 467/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 319.4617 - val_loss: 113.3584\n",
            "Epoch 468/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 366.2331 - val_loss: 112.2901\n",
            "Epoch 469/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 488.0915 - val_loss: 111.1759\n",
            "Epoch 470/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 310.6440 - val_loss: 110.1254\n",
            "Epoch 471/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 392.0420 - val_loss: 109.7430\n",
            "Epoch 472/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 219.5686 - val_loss: 109.4220\n",
            "Epoch 473/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 298.1625 - val_loss: 108.9044\n",
            "Epoch 474/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 383.8657 - val_loss: 108.7030\n",
            "Epoch 475/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 253.0526 - val_loss: 108.9075\n",
            "Epoch 476/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 386.7326 - val_loss: 108.4984\n",
            "Epoch 477/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 333.6464 - val_loss: 107.9070\n",
            "Epoch 478/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 325.0847 - val_loss: 107.1179\n",
            "Epoch 479/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 284.4612 - val_loss: 106.6002\n",
            "Epoch 480/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 439.8094 - val_loss: 106.3937\n",
            "Epoch 481/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 358.9647 - val_loss: 106.4622\n",
            "Epoch 482/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 236.9932 - val_loss: 107.1750\n",
            "Epoch 483/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 359.7884 - val_loss: 108.2865\n",
            "Epoch 484/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 403.0415 - val_loss: 109.7353\n",
            "Epoch 485/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 434.8497 - val_loss: 110.9489\n",
            "Epoch 486/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 329.7843 - val_loss: 112.5269\n",
            "Epoch 487/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 258.4276 - val_loss: 114.3122\n",
            "Epoch 488/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 337.5081 - val_loss: 115.3353\n",
            "Epoch 489/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 313.1494 - val_loss: 115.4573\n",
            "Epoch 490/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 346.3070 - val_loss: 114.8782\n",
            "Epoch 491/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 349.3239 - val_loss: 114.0110\n",
            "Epoch 492/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 342.2017 - val_loss: 113.5854\n",
            "Epoch 493/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 396.5880 - val_loss: 113.5216\n",
            "Epoch 494/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 264.4572 - val_loss: 113.4903\n",
            "Epoch 495/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 231.1371 - val_loss: 112.8279\n",
            "Epoch 496/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 264.7090 - val_loss: 111.7082\n",
            "Epoch 497/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 264.4067 - val_loss: 110.4057\n",
            "Epoch 498/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 374.3060 - val_loss: 109.5585\n",
            "Epoch 499/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 299.1064 - val_loss: 109.3786\n",
            "Epoch 500/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 453.1981 - val_loss: 108.3685\n",
            "Epoch 501/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 255.5191 - val_loss: 107.7563\n",
            "Epoch 502/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 408.2053 - val_loss: 107.7643\n",
            "Epoch 503/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 288.5372 - val_loss: 108.2821\n",
            "Epoch 504/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 248.2598 - val_loss: 108.5411\n",
            "Epoch 505/1000\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 254.3128 - val_loss: 108.6301\n",
            "Epoch 506/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 300.5077 - val_loss: 108.5963\n",
            "Epoch 507/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 239.6518 - val_loss: 108.7301\n",
            "Epoch 508/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 228.4965 - val_loss: 109.1096\n",
            "Epoch 509/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 200.2218 - val_loss: 109.4092\n",
            "Epoch 510/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 280.3023 - val_loss: 109.1556\n",
            "Epoch 511/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 260.1923 - val_loss: 108.5626\n",
            "Epoch 512/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 295.0915 - val_loss: 108.1909\n",
            "Epoch 513/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 426.5276 - val_loss: 107.6840\n",
            "Epoch 514/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 349.7112 - val_loss: 106.9955\n",
            "Epoch 515/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 265.0332 - val_loss: 106.3294\n",
            "Epoch 516/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 278.8146 - val_loss: 105.6354\n",
            "Epoch 517/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 354.4085 - val_loss: 105.0421\n",
            "Epoch 518/1000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 357.9818 - val_loss: 104.9132\n",
            "Epoch 519/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 290.6418 - val_loss: 104.7484\n",
            "Epoch 520/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 305.1801 - val_loss: 105.2334\n",
            "Epoch 521/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 330.5396 - val_loss: 105.3449\n",
            "Epoch 522/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 365.1949 - val_loss: 104.6080\n",
            "Epoch 523/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 376.3972 - val_loss: 104.7354\n",
            "Epoch 524/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 313.4695 - val_loss: 105.0369\n",
            "Epoch 525/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 444.6662 - val_loss: 105.4815\n",
            "Epoch 526/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 321.6017 - val_loss: 105.8210\n",
            "Epoch 527/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 214.8934 - val_loss: 106.0578\n",
            "Epoch 528/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 222.1313 - val_loss: 106.1133\n",
            "Epoch 529/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 287.9395 - val_loss: 106.1777\n",
            "Epoch 530/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 412.2673 - val_loss: 105.8204\n",
            "Epoch 531/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 221.1464 - val_loss: 105.2403\n",
            "Epoch 532/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 262.5069 - val_loss: 104.6504\n",
            "Epoch 533/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 258.8944 - val_loss: 104.1392\n",
            "Epoch 534/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 304.4518 - val_loss: 103.3906\n",
            "Epoch 535/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 307.0553 - val_loss: 102.5440\n",
            "Epoch 536/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 336.3864 - val_loss: 102.1163\n",
            "Epoch 537/1000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 384.6875 - val_loss: 101.4017\n",
            "Epoch 538/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 288.5413 - val_loss: 101.0286\n",
            "Epoch 539/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 284.9647 - val_loss: 100.9000\n",
            "Epoch 540/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 337.2541 - val_loss: 100.9450\n",
            "Epoch 541/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 335.0415 - val_loss: 101.1004\n",
            "Epoch 542/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 327.9550 - val_loss: 101.3310\n",
            "Epoch 543/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 232.4871 - val_loss: 101.5299\n",
            "Epoch 544/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 439.8579 - val_loss: 101.3565\n",
            "Epoch 545/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 421.4476 - val_loss: 100.9725\n",
            "Epoch 546/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 304.9904 - val_loss: 100.6768\n",
            "Epoch 547/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 395.9582 - val_loss: 100.4916\n",
            "Epoch 548/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 369.1513 - val_loss: 100.5880\n",
            "Epoch 549/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 312.4189 - val_loss: 101.3473\n",
            "Epoch 550/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 346.0851 - val_loss: 102.9610\n",
            "Epoch 551/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 292.9633 - val_loss: 103.8029\n",
            "Epoch 552/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 326.5386 - val_loss: 103.8179\n",
            "Epoch 553/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 201.8464 - val_loss: 102.1798\n",
            "Epoch 554/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 316.4849 - val_loss: 100.8677\n",
            "Epoch 555/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 303.6208 - val_loss: 99.8923\n",
            "Epoch 556/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 305.9304 - val_loss: 99.9313\n",
            "Epoch 557/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 330.1414 - val_loss: 100.8924\n",
            "Epoch 558/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 271.6415 - val_loss: 101.9313\n",
            "Epoch 559/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 250.2291 - val_loss: 103.4472\n",
            "Epoch 560/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 473.2299 - val_loss: 104.3785\n",
            "Epoch 561/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 309.2436 - val_loss: 104.8316\n",
            "Epoch 562/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 353.4858 - val_loss: 104.7889\n",
            "Epoch 563/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 345.0772 - val_loss: 103.7004\n",
            "Epoch 564/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 397.4260 - val_loss: 102.3982\n",
            "Epoch 565/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 317.9392 - val_loss: 102.5626\n",
            "Epoch 566/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 343.0547 - val_loss: 104.2294\n",
            "Epoch 567/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 214.9459 - val_loss: 107.2101\n",
            "Epoch 568/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 348.5363 - val_loss: 110.3563\n",
            "Epoch 569/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 284.4796 - val_loss: 113.1380\n",
            "Epoch 570/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 456.5286 - val_loss: 112.6763\n",
            "Epoch 571/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 298.6301 - val_loss: 110.1376\n",
            "Epoch 572/1000\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 278.2628 - val_loss: 107.1989\n",
            "Epoch 573/1000\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 223.2970 - val_loss: 105.4526\n",
            "Epoch 574/1000\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 328.6341 - val_loss: 106.6407\n",
            "Epoch 575/1000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 287.1777 - val_loss: 109.3306\n",
            "Epoch 576/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 278.6566 - val_loss: 112.7840\n",
            "Epoch 577/1000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 188.3882 - val_loss: 118.1034\n",
            "Epoch 578/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 307.4452 - val_loss: 121.2661\n",
            "Epoch 579/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 366.9028 - val_loss: 120.2530\n",
            "Epoch 580/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 353.0079 - val_loss: 116.6651\n",
            "Epoch 581/1000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 446.1035 - val_loss: 111.7806\n",
            "Epoch 582/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 386.4401 - val_loss: 107.1199\n",
            "Epoch 583/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 344.5269 - val_loss: 103.6433\n",
            "Epoch 584/1000\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 234.0697 - val_loss: 102.1291\n",
            "Epoch 585/1000\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 389.9696 - val_loss: 101.6863\n",
            "Epoch 586/1000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 296.9640 - val_loss: 101.5721\n",
            "Epoch 587/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 216.2339 - val_loss: 101.6040\n",
            "Epoch 588/1000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 306.8319 - val_loss: 102.0885\n",
            "Epoch 589/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 350.3823 - val_loss: 101.9113\n",
            "Epoch 590/1000\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 258.0864 - val_loss: 100.6599\n",
            "Epoch 591/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 360.7456 - val_loss: 98.2096\n",
            "Epoch 592/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 309.0379 - val_loss: 96.2994\n",
            "Epoch 593/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 276.5496 - val_loss: 96.1785\n",
            "Epoch 594/1000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 329.7327 - val_loss: 96.9412\n",
            "Epoch 595/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 301.7627 - val_loss: 97.7519\n",
            "Epoch 596/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 364.5173 - val_loss: 98.3892\n",
            "Epoch 597/1000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 372.9763 - val_loss: 99.5684\n",
            "Epoch 598/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 330.4241 - val_loss: 100.9481\n",
            "Epoch 599/1000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 248.6864 - val_loss: 101.9642\n",
            "Epoch 600/1000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 435.4244 - val_loss: 101.4311\n",
            "Epoch 601/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 291.2202 - val_loss: 100.1264\n",
            "Epoch 602/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 351.7417 - val_loss: 98.3259\n",
            "Epoch 603/1000\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 301.9055 - val_loss: 96.3024\n",
            "Epoch 604/1000\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 321.4381 - val_loss: 95.5423\n",
            "Epoch 605/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 322.7664 - val_loss: 95.4916\n",
            "Epoch 606/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 244.1756 - val_loss: 95.9716\n",
            "Epoch 607/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 352.2251 - val_loss: 97.5802\n",
            "Epoch 608/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 312.7036 - val_loss: 100.7616\n",
            "Epoch 609/1000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 416.4668 - val_loss: 103.1276\n",
            "Epoch 610/1000\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 307.2021 - val_loss: 104.0006\n",
            "Epoch 611/1000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 295.9924 - val_loss: 102.3791\n",
            "Epoch 612/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 314.3930 - val_loss: 98.9473\n",
            "Epoch 613/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 296.8861 - val_loss: 95.6067\n",
            "Epoch 614/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 273.5937 - val_loss: 94.0647\n",
            "Epoch 615/1000\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 368.7762 - val_loss: 93.7060\n",
            "Epoch 616/1000\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 315.2346 - val_loss: 93.7374\n",
            "Epoch 617/1000\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 203.3239 - val_loss: 94.2050\n",
            "Epoch 618/1000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 318.3891 - val_loss: 95.4589\n",
            "Epoch 619/1000\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 258.7665 - val_loss: 97.6606\n",
            "Epoch 620/1000\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 331.9171 - val_loss: 99.0211\n",
            "Epoch 621/1000\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 277.4920 - val_loss: 98.4986\n",
            "Epoch 622/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 310.3435 - val_loss: 97.8035\n",
            "Epoch 623/1000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 383.1662 - val_loss: 96.3726\n",
            "Epoch 624/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 382.0965 - val_loss: 93.5858\n",
            "Epoch 625/1000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 320.9067 - val_loss: 92.8682\n",
            "Epoch 626/1000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 319.2866 - val_loss: 93.0515\n",
            "Epoch 627/1000\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 251.9409 - val_loss: 93.5404\n",
            "Epoch 628/1000\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 347.1037 - val_loss: 94.6081\n",
            "Epoch 629/1000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 277.8449 - val_loss: 95.7025\n",
            "Epoch 630/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 235.9438 - val_loss: 96.6298\n",
            "Epoch 631/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 237.3921 - val_loss: 97.5241\n",
            "Epoch 632/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 300.7352 - val_loss: 98.1558\n",
            "Epoch 633/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 306.1368 - val_loss: 98.6634\n",
            "Epoch 634/1000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 410.5208 - val_loss: 98.5784\n",
            "Epoch 635/1000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 288.6502 - val_loss: 98.7153\n",
            "Epoch 636/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 257.5395 - val_loss: 99.0705\n",
            "Epoch 637/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 191.3438 - val_loss: 99.6781\n",
            "Epoch 638/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 319.7800 - val_loss: 100.1681\n",
            "Epoch 639/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 259.2274 - val_loss: 100.4784\n",
            "Epoch 640/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 218.1859 - val_loss: 100.8018\n",
            "Epoch 641/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 347.8507 - val_loss: 101.0040\n",
            "Epoch 642/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 306.2437 - val_loss: 101.0218\n",
            "Epoch 643/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 505.2866 - val_loss: 100.3140\n",
            "Epoch 644/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 335.4207 - val_loss: 99.9641\n",
            "Epoch 645/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 373.9738 - val_loss: 100.3900\n",
            "Epoch 646/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 256.1131 - val_loss: 102.3281\n",
            "Epoch 647/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 228.0514 - val_loss: 103.9485\n",
            "Epoch 648/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 318.3477 - val_loss: 105.5109\n",
            "Epoch 649/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 349.4171 - val_loss: 105.6528\n",
            "Epoch 650/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 225.8707 - val_loss: 104.0394\n",
            "Epoch 651/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 297.8427 - val_loss: 100.7162\n",
            "Epoch 652/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 278.9704 - val_loss: 97.4195\n",
            "Epoch 653/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 311.2285 - val_loss: 96.2951\n",
            "Epoch 654/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 301.4064 - val_loss: 95.0230\n",
            "Epoch 655/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 419.3037 - val_loss: 94.7099\n",
            "Epoch 656/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 357.1266 - val_loss: 94.2715\n",
            "Epoch 657/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 306.8402 - val_loss: 92.6831\n",
            "Epoch 658/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 214.5543 - val_loss: 91.3893\n",
            "Epoch 659/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 289.4702 - val_loss: 90.8012\n",
            "Epoch 660/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 273.4487 - val_loss: 91.3248\n",
            "Epoch 661/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 288.4234 - val_loss: 91.3738\n",
            "Epoch 662/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 360.0069 - val_loss: 91.0983\n",
            "Epoch 663/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 253.0738 - val_loss: 91.3325\n",
            "Epoch 664/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 347.4871 - val_loss: 91.5288\n",
            "Epoch 665/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 296.3477 - val_loss: 91.5556\n",
            "Epoch 666/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 348.1395 - val_loss: 91.0857\n",
            "Epoch 667/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 251.3379 - val_loss: 90.2046\n",
            "Epoch 668/1000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 280.9861 - val_loss: 89.1583\n",
            "Epoch 669/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 283.3991 - val_loss: 87.8044\n",
            "Epoch 670/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 239.1532 - val_loss: 86.9343\n",
            "Epoch 671/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 281.7081 - val_loss: 86.3764\n",
            "Epoch 672/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 210.2342 - val_loss: 86.1547\n",
            "Epoch 673/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 289.0552 - val_loss: 86.0379\n",
            "Epoch 674/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 372.8811 - val_loss: 86.1606\n",
            "Epoch 675/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 287.2161 - val_loss: 85.9144\n",
            "Epoch 676/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 400.7812 - val_loss: 85.5072\n",
            "Epoch 677/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 298.8651 - val_loss: 85.3641\n",
            "Epoch 678/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 214.8685 - val_loss: 85.7265\n",
            "Epoch 679/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 300.5427 - val_loss: 86.6285\n",
            "Epoch 680/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 330.1805 - val_loss: 89.3119\n",
            "Epoch 681/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 270.2236 - val_loss: 93.1431\n",
            "Epoch 682/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 356.2617 - val_loss: 96.0820\n",
            "Epoch 683/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 403.3003 - val_loss: 96.7953\n",
            "Epoch 684/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 340.2235 - val_loss: 95.9953\n",
            "Epoch 685/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 343.4968 - val_loss: 93.8806\n",
            "Epoch 686/1000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 282.7532 - val_loss: 92.7829\n",
            "Epoch 687/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 233.2011 - val_loss: 92.4773\n",
            "Epoch 688/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 282.7889 - val_loss: 92.6814\n",
            "Epoch 689/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 216.4272 - val_loss: 92.4437\n",
            "Epoch 690/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 281.8856 - val_loss: 92.1178\n",
            "Epoch 691/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 207.9736 - val_loss: 90.9603\n",
            "Epoch 692/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 436.9535 - val_loss: 89.2137\n",
            "Epoch 693/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 242.0668 - val_loss: 87.2785\n",
            "Epoch 694/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 234.5001 - val_loss: 85.7603\n",
            "Epoch 695/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 309.1624 - val_loss: 84.8164\n",
            "Epoch 696/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 268.5835 - val_loss: 83.3600\n",
            "Epoch 697/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 300.4655 - val_loss: 82.5474\n",
            "Epoch 698/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 244.4260 - val_loss: 81.7498\n",
            "Epoch 699/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 304.4457 - val_loss: 80.6614\n",
            "Epoch 700/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 323.9200 - val_loss: 79.6076\n",
            "Epoch 701/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 300.8149 - val_loss: 79.1078\n",
            "Epoch 702/1000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 276.6877 - val_loss: 79.2774\n",
            "Epoch 703/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 228.4161 - val_loss: 79.7657\n",
            "Epoch 704/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 310.6808 - val_loss: 80.4824\n",
            "Epoch 705/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 295.6382 - val_loss: 81.3667\n",
            "Epoch 706/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 243.3535 - val_loss: 82.5396\n",
            "Epoch 707/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 278.0976 - val_loss: 83.8336\n",
            "Epoch 708/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 326.1826 - val_loss: 85.3005\n",
            "Epoch 709/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 321.9156 - val_loss: 86.9335\n",
            "Epoch 710/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 181.8095 - val_loss: 89.1765\n",
            "Epoch 711/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 282.9566 - val_loss: 90.8887\n",
            "Epoch 712/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 291.6249 - val_loss: 92.9431\n",
            "Epoch 713/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 245.0036 - val_loss: 94.8261\n",
            "Epoch 714/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 325.9386 - val_loss: 94.7295\n",
            "Epoch 715/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 399.2594 - val_loss: 93.4986\n",
            "Epoch 716/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 313.0195 - val_loss: 92.0078\n",
            "Epoch 717/1000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 195.1346 - val_loss: 89.4949\n",
            "Epoch 718/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 268.3376 - val_loss: 86.7818\n",
            "Epoch 719/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 296.8980 - val_loss: 84.4773\n",
            "Epoch 720/1000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 205.2023 - val_loss: 82.9511\n",
            "Epoch 721/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 208.1254 - val_loss: 82.3228\n",
            "Epoch 722/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 209.6166 - val_loss: 81.8089\n",
            "Epoch 723/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 329.6109 - val_loss: 81.5935\n",
            "Epoch 724/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 183.4181 - val_loss: 82.2965\n",
            "Epoch 725/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 192.4030 - val_loss: 83.4365\n",
            "Epoch 726/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 271.5448 - val_loss: 83.4170\n",
            "Epoch 727/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 357.3188 - val_loss: 82.3572\n",
            "Epoch 728/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 288.9225 - val_loss: 81.6085\n",
            "Epoch 729/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 288.4484 - val_loss: 80.8671\n",
            "Epoch 730/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 251.1311 - val_loss: 80.9029\n",
            "Epoch 731/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 316.1246 - val_loss: 81.6080\n",
            "Epoch 732/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 241.1461 - val_loss: 82.5941\n",
            "Epoch 733/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 294.1851 - val_loss: 83.0614\n",
            "Epoch 734/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 272.9598 - val_loss: 83.4946\n",
            "Epoch 735/1000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 349.6162 - val_loss: 84.0489\n",
            "Epoch 736/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 318.8748 - val_loss: 84.8353\n",
            "Epoch 737/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 210.5300 - val_loss: 85.2883\n",
            "Epoch 738/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 237.4248 - val_loss: 86.3758\n",
            "Epoch 739/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 265.0229 - val_loss: 87.1392\n",
            "Epoch 740/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 268.5391 - val_loss: 87.6759\n",
            "Epoch 741/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 250.9756 - val_loss: 89.9872\n",
            "Epoch 742/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 173.7997 - val_loss: 92.5486\n",
            "Epoch 743/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 387.9506 - val_loss: 93.2849\n",
            "Epoch 744/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 324.6194 - val_loss: 92.8540\n",
            "Epoch 745/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 225.5012 - val_loss: 91.0612\n",
            "Epoch 746/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 236.9686 - val_loss: 90.2191\n",
            "Epoch 747/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 318.8723 - val_loss: 90.0977\n",
            "Epoch 748/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 610.4669 - val_loss: 89.6881\n",
            "Epoch 749/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 191.9543 - val_loss: 88.8047\n",
            "Epoch 750/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 277.5515 - val_loss: 87.0251\n",
            "Epoch 751/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 250.9384 - val_loss: 84.6920\n",
            "Epoch 752/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 294.7991 - val_loss: 82.1016\n",
            "Epoch 753/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 353.0207 - val_loss: 79.8458\n",
            "Epoch 754/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 310.1106 - val_loss: 78.3395\n",
            "Epoch 755/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 245.5621 - val_loss: 77.9386\n",
            "Epoch 756/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 436.2800 - val_loss: 77.8342\n",
            "Epoch 757/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 346.1049 - val_loss: 77.6221\n",
            "Epoch 758/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 278.0214 - val_loss: 78.1184\n",
            "Epoch 759/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 248.9190 - val_loss: 77.9830\n",
            "Epoch 760/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 270.3033 - val_loss: 77.9188\n",
            "Epoch 761/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 419.6323 - val_loss: 77.7844\n",
            "Epoch 762/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 255.8275 - val_loss: 77.7645\n",
            "Epoch 763/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 240.7605 - val_loss: 78.4097\n",
            "Epoch 764/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 272.2173 - val_loss: 78.8170\n",
            "Epoch 765/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 283.6493 - val_loss: 79.1090\n",
            "Epoch 766/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 302.7856 - val_loss: 78.9130\n",
            "Epoch 767/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 248.8558 - val_loss: 78.8262\n",
            "Epoch 768/1000\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 304.1920 - val_loss: 79.4940\n",
            "Epoch 769/1000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 270.9556 - val_loss: 81.7476\n",
            "Epoch 770/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 248.9415 - val_loss: 83.4576\n",
            "Epoch 771/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 253.5416 - val_loss: 84.2341\n",
            "Epoch 772/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 329.4052 - val_loss: 83.2371\n",
            "Epoch 773/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 256.4637 - val_loss: 80.9523\n",
            "Epoch 774/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 191.9903 - val_loss: 79.0831\n",
            "Epoch 775/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 261.1324 - val_loss: 77.6373\n",
            "Epoch 776/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 299.4959 - val_loss: 76.5633\n",
            "Epoch 777/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 326.3140 - val_loss: 77.2380\n",
            "Epoch 778/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 289.2014 - val_loss: 78.8126\n",
            "Epoch 779/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 236.1646 - val_loss: 80.4005\n",
            "Epoch 780/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 318.0096 - val_loss: 80.8605\n",
            "Epoch 781/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 218.3271 - val_loss: 79.8167\n",
            "Epoch 782/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 311.8539 - val_loss: 76.0281\n",
            "Epoch 783/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 241.4302 - val_loss: 74.7139\n",
            "Epoch 784/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 239.8935 - val_loss: 81.1072\n",
            "Epoch 785/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 328.8846 - val_loss: 84.5750\n",
            "Epoch 786/1000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 472.4184 - val_loss: 80.3538\n",
            "Epoch 787/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 358.5996 - val_loss: 78.2666\n",
            "Epoch 788/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 363.7077 - val_loss: 76.6726\n",
            "Epoch 789/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 243.7870 - val_loss: 75.8096\n",
            "Epoch 790/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 243.6163 - val_loss: 74.0647\n",
            "Epoch 791/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 251.5095 - val_loss: 72.4028\n",
            "Epoch 792/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 275.4402 - val_loss: 72.9418\n",
            "Epoch 793/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 231.8494 - val_loss: 74.5084\n",
            "Epoch 794/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 251.8682 - val_loss: 71.7562\n",
            "Epoch 795/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 264.2250 - val_loss: 67.8168\n",
            "Epoch 796/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 202.8299 - val_loss: 64.3938\n",
            "Epoch 797/1000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 246.5087 - val_loss: 62.7459\n",
            "Epoch 798/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 189.8229 - val_loss: 61.6607\n",
            "Epoch 799/1000\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 212.8549 - val_loss: 60.8099\n",
            "Epoch 800/1000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 175.3421 - val_loss: 60.0745\n",
            "Epoch 801/1000\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 253.0253 - val_loss: 59.2607\n",
            "Epoch 802/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 188.6161 - val_loss: 58.6881\n",
            "Epoch 803/1000\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 235.7642 - val_loss: 58.2168\n",
            "Epoch 804/1000\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 191.3905 - val_loss: 57.6165\n",
            "Epoch 805/1000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 244.3669 - val_loss: 57.6718\n",
            "Epoch 806/1000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 231.2208 - val_loss: 58.1708\n",
            "Epoch 807/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 284.5243 - val_loss: 58.4780\n",
            "Epoch 808/1000\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 292.4324 - val_loss: 58.2625\n",
            "Epoch 809/1000\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 289.9526 - val_loss: 58.8015\n",
            "Epoch 810/1000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 234.1686 - val_loss: 59.3677\n",
            "Epoch 811/1000\n",
            "2/2 [==============================] - 0s 97ms/step - loss: 258.3140 - val_loss: 58.1309\n",
            "Epoch 812/1000\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 231.4522 - val_loss: 57.1005\n",
            "Epoch 813/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 229.8287 - val_loss: 56.4599\n",
            "Epoch 814/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 237.5150 - val_loss: 56.2134\n",
            "Epoch 815/1000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 267.8576 - val_loss: 56.4032\n",
            "Epoch 816/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 224.2414 - val_loss: 56.4575\n",
            "Epoch 817/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 186.6732 - val_loss: 56.8221\n",
            "Epoch 818/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 167.5886 - val_loss: 56.9894\n",
            "Epoch 819/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 147.4611 - val_loss: 57.2488\n",
            "Epoch 820/1000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 260.4654 - val_loss: 57.6234\n",
            "Epoch 821/1000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 207.6170 - val_loss: 57.5893\n",
            "Epoch 822/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 240.1148 - val_loss: 57.1588\n",
            "Epoch 823/1000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 272.9780 - val_loss: 56.4437\n",
            "Epoch 824/1000\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 246.4919 - val_loss: 56.2089\n",
            "Epoch 825/1000\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 291.9254 - val_loss: 55.5994\n",
            "Epoch 826/1000\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 212.9964 - val_loss: 55.4604\n",
            "Epoch 827/1000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 172.3703 - val_loss: 55.6495\n",
            "Epoch 828/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 269.3955 - val_loss: 55.5004\n",
            "Epoch 829/1000\n",
            "2/2 [==============================] - 0s 94ms/step - loss: 192.3506 - val_loss: 55.5087\n",
            "Epoch 830/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 293.2317 - val_loss: 55.6293\n",
            "Epoch 831/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 271.2201 - val_loss: 56.4294\n",
            "Epoch 832/1000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 222.7696 - val_loss: 57.7247\n",
            "Epoch 833/1000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 193.9814 - val_loss: 60.1521\n",
            "Epoch 834/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 252.0271 - val_loss: 63.8221\n",
            "Epoch 835/1000\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 230.4371 - val_loss: 62.4188\n",
            "Epoch 836/1000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 283.5223 - val_loss: 61.1346\n",
            "Epoch 837/1000\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 293.4548 - val_loss: 60.4496\n",
            "Epoch 838/1000\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 296.7851 - val_loss: 58.6240\n",
            "Epoch 839/1000\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 229.3457 - val_loss: 56.8803\n",
            "Epoch 840/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 345.7437 - val_loss: 55.0614\n",
            "Epoch 841/1000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 258.0630 - val_loss: 55.3386\n",
            "Epoch 842/1000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 202.0351 - val_loss: 56.5198\n",
            "Epoch 843/1000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 363.5364 - val_loss: 56.6566\n",
            "Epoch 844/1000\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 278.1043 - val_loss: 56.5017\n",
            "Epoch 845/1000\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 216.9571 - val_loss: 54.9098\n",
            "Epoch 846/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 264.0979 - val_loss: 52.3533\n",
            "Epoch 847/1000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 247.4160 - val_loss: 51.2915\n",
            "Epoch 848/1000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 284.2222 - val_loss: 50.7945\n",
            "Epoch 849/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 215.4026 - val_loss: 50.7130\n",
            "Epoch 850/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 207.8783 - val_loss: 50.4733\n",
            "Epoch 851/1000\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 229.3107 - val_loss: 50.3620\n",
            "Epoch 852/1000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 324.9870 - val_loss: 50.0854\n",
            "Epoch 853/1000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 178.6485 - val_loss: 48.7042\n",
            "Epoch 854/1000\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 275.6160 - val_loss: 47.6004\n",
            "Epoch 855/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 318.1049 - val_loss: 47.1606\n",
            "Epoch 856/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 193.4323 - val_loss: 47.1447\n",
            "Epoch 857/1000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 250.8258 - val_loss: 48.0233\n",
            "Epoch 858/1000\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 307.0182 - val_loss: 49.3795\n",
            "Epoch 859/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 301.1371 - val_loss: 50.1475\n",
            "Epoch 860/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 195.5295 - val_loss: 51.5150\n",
            "Epoch 861/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 200.7662 - val_loss: 53.5062\n",
            "Epoch 862/1000\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 190.6651 - val_loss: 57.9664\n",
            "Epoch 863/1000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 245.2613 - val_loss: 63.1874\n",
            "Epoch 864/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 274.0010 - val_loss: 65.1544\n",
            "Epoch 865/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 135.2486 - val_loss: 66.0801\n",
            "Epoch 866/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 216.7949 - val_loss: 63.9928\n",
            "Epoch 867/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 245.6803 - val_loss: 57.7817\n",
            "Epoch 868/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 224.8859 - val_loss: 52.6276\n",
            "Epoch 869/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 170.3076 - val_loss: 50.0965\n",
            "Epoch 870/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 345.2327 - val_loss: 47.4426\n",
            "Epoch 871/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 211.5389 - val_loss: 47.6623\n",
            "Epoch 872/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 277.8508 - val_loss: 49.3731\n",
            "Epoch 873/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 277.3109 - val_loss: 49.7780\n",
            "Epoch 874/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 173.5436 - val_loss: 50.3714\n",
            "Epoch 875/1000\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 293.7413 - val_loss: 50.8310\n",
            "Epoch 876/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 167.6611 - val_loss: 49.2015\n",
            "Epoch 877/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 227.6913 - val_loss: 47.5317\n",
            "Epoch 878/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 241.7744 - val_loss: 46.5287\n",
            "Epoch 879/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 259.3232 - val_loss: 47.2063\n",
            "Epoch 880/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 251.8780 - val_loss: 48.1347\n",
            "Epoch 881/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 284.3823 - val_loss: 47.8681\n",
            "Epoch 882/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 250.0175 - val_loss: 46.9946\n",
            "Epoch 883/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 196.4880 - val_loss: 46.5583\n",
            "Epoch 884/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 295.2243 - val_loss: 46.6389\n",
            "Epoch 885/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 241.4761 - val_loss: 47.1286\n",
            "Epoch 886/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 324.1429 - val_loss: 48.2039\n",
            "Epoch 887/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 234.8983 - val_loss: 48.6811\n",
            "Epoch 888/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 247.5557 - val_loss: 48.9866\n",
            "Epoch 889/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 172.8813 - val_loss: 49.9316\n",
            "Epoch 890/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 213.4579 - val_loss: 51.1034\n",
            "Epoch 891/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 205.2902 - val_loss: 51.6666\n",
            "Epoch 892/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 233.1884 - val_loss: 52.6196\n",
            "Epoch 893/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 213.1444 - val_loss: 53.9228\n",
            "Epoch 894/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 248.0407 - val_loss: 52.5170\n",
            "Epoch 895/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 276.9059 - val_loss: 50.4211\n",
            "Epoch 896/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 284.4870 - val_loss: 47.7564\n",
            "Epoch 897/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 243.4127 - val_loss: 46.4721\n",
            "Epoch 898/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 271.8214 - val_loss: 45.9413\n",
            "Epoch 899/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 141.1122 - val_loss: 45.7725\n",
            "Epoch 900/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 210.1638 - val_loss: 46.4296\n",
            "Epoch 901/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 204.6211 - val_loss: 49.8397\n",
            "Epoch 902/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 307.5592 - val_loss: 55.9344\n",
            "Epoch 903/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 289.5577 - val_loss: 60.9813\n",
            "Epoch 904/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 272.1023 - val_loss: 62.2646\n",
            "Epoch 905/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 166.5416 - val_loss: 58.7344\n",
            "Epoch 906/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 278.4413 - val_loss: 53.6126\n",
            "Epoch 907/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 224.8135 - val_loss: 49.6902\n",
            "Epoch 908/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 204.0177 - val_loss: 49.0666\n",
            "Epoch 909/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 245.6488 - val_loss: 49.7597\n",
            "Epoch 910/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 221.2764 - val_loss: 52.1414\n",
            "Epoch 911/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 204.7736 - val_loss: 55.1893\n",
            "Epoch 912/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 497.4301 - val_loss: 52.7145\n",
            "Epoch 913/1000\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 215.2149 - val_loss: 48.6763\n",
            "Epoch 914/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 280.7804 - val_loss: 46.4906\n",
            "Epoch 915/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 312.7361 - val_loss: 45.3387\n",
            "Epoch 916/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 296.3432 - val_loss: 44.1121\n",
            "Epoch 917/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 231.4135 - val_loss: 43.1726\n",
            "Epoch 918/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 185.5998 - val_loss: 42.6454\n",
            "Epoch 919/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 297.4166 - val_loss: 42.5214\n",
            "Epoch 920/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 232.2807 - val_loss: 42.7105\n",
            "Epoch 921/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 185.4672 - val_loss: 43.3538\n",
            "Epoch 922/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 188.8633 - val_loss: 43.6078\n",
            "Epoch 923/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 214.9544 - val_loss: 43.4031\n",
            "Epoch 924/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 210.1853 - val_loss: 43.1705\n",
            "Epoch 925/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 233.6665 - val_loss: 43.2090\n",
            "Epoch 926/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 179.0461 - val_loss: 44.1834\n",
            "Epoch 927/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 203.4944 - val_loss: 46.3052\n",
            "Epoch 928/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 245.7793 - val_loss: 46.6885\n",
            "Epoch 929/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 207.9041 - val_loss: 47.5733\n",
            "Epoch 930/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 164.6539 - val_loss: 48.4643\n",
            "Epoch 931/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 184.4635 - val_loss: 49.4616\n",
            "Epoch 932/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 226.7972 - val_loss: 50.5389\n",
            "Epoch 933/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 231.4755 - val_loss: 50.0094\n",
            "Epoch 934/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 235.4800 - val_loss: 48.6875\n",
            "Epoch 935/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 252.0125 - val_loss: 46.6321\n",
            "Epoch 936/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 254.1865 - val_loss: 44.5525\n",
            "Epoch 937/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 238.2331 - val_loss: 42.9018\n",
            "Epoch 938/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 357.2903 - val_loss: 42.9175\n",
            "Epoch 939/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 197.5485 - val_loss: 43.7079\n",
            "Epoch 940/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 283.1935 - val_loss: 43.3846\n",
            "Epoch 941/1000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 269.7369 - val_loss: 43.4686\n",
            "Epoch 942/1000\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 316.8522 - val_loss: 43.9141\n",
            "Epoch 943/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 312.2080 - val_loss: 43.9480\n",
            "Epoch 944/1000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 246.2967 - val_loss: 43.5676\n",
            "Epoch 945/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 191.1006 - val_loss: 43.4112\n",
            "Epoch 946/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 216.4390 - val_loss: 43.6420\n",
            "Epoch 947/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 253.6071 - val_loss: 44.5791\n",
            "Epoch 948/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 216.3320 - val_loss: 46.3112\n",
            "Epoch 949/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 211.4951 - val_loss: 47.0997\n",
            "Epoch 950/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 251.5020 - val_loss: 45.8578\n",
            "Epoch 951/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 188.3412 - val_loss: 45.0652\n",
            "Epoch 952/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 153.7476 - val_loss: 45.5492\n",
            "Epoch 953/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 212.7819 - val_loss: 45.8526\n",
            "Epoch 954/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 237.9310 - val_loss: 47.1365\n",
            "Epoch 955/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 222.0679 - val_loss: 46.2185\n",
            "Epoch 956/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 264.2007 - val_loss: 43.6168\n",
            "Epoch 957/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 237.6763 - val_loss: 40.9399\n",
            "Epoch 958/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 207.1279 - val_loss: 40.6010\n",
            "Epoch 959/1000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 317.5219 - val_loss: 42.0559\n",
            "Epoch 960/1000\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 186.0409 - val_loss: 43.2156\n",
            "Epoch 961/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 193.6049 - val_loss: 42.9527\n",
            "Epoch 962/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 168.6637 - val_loss: 41.9632\n",
            "Epoch 963/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 315.7838 - val_loss: 39.3836\n",
            "Epoch 964/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 195.8119 - val_loss: 38.5930\n",
            "Epoch 965/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 240.3865 - val_loss: 39.7049\n",
            "Epoch 966/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 225.7808 - val_loss: 40.5637\n",
            "Epoch 967/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 180.5501 - val_loss: 43.5317\n",
            "Epoch 968/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 152.9116 - val_loss: 47.9822\n",
            "Epoch 969/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 209.6040 - val_loss: 53.0543\n",
            "Epoch 970/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 171.6726 - val_loss: 51.2903\n",
            "Epoch 971/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 207.0340 - val_loss: 46.8381\n",
            "Epoch 972/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 276.8608 - val_loss: 41.0350\n",
            "Epoch 973/1000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 210.9978 - val_loss: 38.0875\n",
            "Epoch 974/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 332.7546 - val_loss: 36.2175\n",
            "Epoch 975/1000\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 154.6685 - val_loss: 34.9985\n",
            "Epoch 976/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 237.0073 - val_loss: 35.0141\n",
            "Epoch 977/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 256.2984 - val_loss: 34.0770\n",
            "Epoch 978/1000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 268.0887 - val_loss: 32.2830\n",
            "Epoch 979/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 209.2323 - val_loss: 32.4505\n",
            "Epoch 980/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 216.2956 - val_loss: 31.4835\n",
            "Epoch 981/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 250.3232 - val_loss: 30.8667\n",
            "Epoch 982/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 178.8804 - val_loss: 32.1754\n",
            "Epoch 983/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 298.8584 - val_loss: 33.8053\n",
            "Epoch 984/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 307.1771 - val_loss: 31.9619\n",
            "Epoch 985/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 214.2637 - val_loss: 30.5829\n",
            "Epoch 986/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 137.2870 - val_loss: 31.0478\n",
            "Epoch 987/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 152.9150 - val_loss: 31.5638\n",
            "Epoch 988/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 331.1747 - val_loss: 30.3447\n",
            "Epoch 989/1000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 252.5492 - val_loss: 29.6408\n",
            "Epoch 990/1000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 149.2141 - val_loss: 29.7911\n",
            "Epoch 991/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 146.3341 - val_loss: 29.6923\n",
            "Epoch 992/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 252.5830 - val_loss: 30.3186\n",
            "Epoch 993/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 170.7669 - val_loss: 29.8261\n",
            "Epoch 994/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 140.2932 - val_loss: 29.5617\n",
            "Epoch 995/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 220.3992 - val_loss: 31.9892\n",
            "Epoch 996/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 195.6178 - val_loss: 32.9380\n",
            "Epoch 997/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 192.5969 - val_loss: 32.6456\n",
            "Epoch 998/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 209.3154 - val_loss: 32.9019\n",
            "Epoch 999/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 189.0552 - val_loss: 33.2620\n",
            "Epoch 1000/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 267.3799 - val_loss: 32.7709\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 32.7709\n",
            "Perdida: 32.770877838134766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluar el modelo\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title(\"Funcion de perdida\")\n",
        "plt.xlabel(\"# Epoca\")\n",
        "plt.ylabel(\"Magnitud de perdida\")\n",
        "plt.plot(historial.history[\"loss\"], label='Entrenamiento')\n",
        "plt.plot(historial.history['val_loss'], label='ValidaciÃ³n')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "dgoG6zy68pWW",
        "outputId": "d4fd5461-0d9c-41a1-d129-d03008974265"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predecir la distancia recorrida para los siguientes datos:\n",
        "#1) Velocidad = 55Km/h, Tiempo = 1.2h\n",
        "#2) Velocidad = 75Km/h, Tiempo = 3h\n",
        "#3) Velocidad = 60Km/h, Tiempo = 2h\n",
        "datos_prueba = pd.DataFrame(\n",
        "  {'Velocidad': [55, 75, 60],\n",
        "    'Tiempo': [1.2, 3, 2]}\n",
        ")\n",
        "\n",
        "# Normalizar los datos de prueba\n",
        "datos_prueba_n = scaler.transform(datos_prueba)\n",
        "\n",
        "# Predecir las distancias recorridas en base a los datos normalizados\n",
        "predicciones = modelo.predict(datos_prueba_n)\n",
        "\n",
        "# Mostrar las predicciones\n",
        "print(\"Predicciones de distancias para:\")\n",
        "for i, (velocidad, tiempo, prediccion) in enumerate(zip(datos_prueba['Velocidad'], datos_prueba['Tiempo'], predicciones), 1):\n",
        "    print(f\"{i}) Velocidad: {velocidad} * Tiempo: {tiempo} = {prediccion[0]}\")\n",
        "\n",
        "print(\"Distancias reales para:\")\n",
        "for i, (velocidad, tiempo) in enumerate(zip(datos_prueba['Velocidad'], datos_prueba['Tiempo']), 1):\n",
        "    print(f\"{i}) Velocidad: {velocidad} * Tiempo: {tiempo} = {velocidad*tiempo}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqI7yolw8r3X",
        "outputId": "5864d839-15ba-49ee-b6cc-7984d6466381"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 114ms/step\n",
            "Predicciones de distancias para:\n",
            "1) Velocidad: 55 * Tiempo: 1.2 = 65.80057525634766\n",
            "2) Velocidad: 75 * Tiempo: 3.0 = 219.73826599121094\n",
            "3) Velocidad: 60 * Tiempo: 2.0 = 120.97848510742188\n",
            "Distancias reales para:\n",
            "1) Velocidad: 55 * Tiempo: 1.2 = 66.0\n",
            "2) Velocidad: 75 * Tiempo: 3.0 = 225.0\n",
            "3) Velocidad: 60 * Tiempo: 2.0 = 120.0\n"
          ]
        }
      ]
    }
  ]
}